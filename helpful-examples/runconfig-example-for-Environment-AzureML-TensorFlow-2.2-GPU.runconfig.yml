# The script to run.
script: example-tensorflow-train-mnist.py
# The arguments to the script file.
arguments: []
# The name of the compute target to use for this run.
target: local
# Framework to execute inside. Allowed values are "Python" ,  "PySpark", "CNTK",  "TensorFlow", and "PyTorch".
framework: TensorFlow
# Communicator for the given framework. Allowed values are "None" ,  "ParameterServer", "OpenMpi", and "IntelMpi".
communicator: OpenMpi
# Maximum allowed duration for the run.
maxRunDurationSeconds:
# Number of nodes to use for running job.
nodeCount: 1
# Environment details.
environment:
{
    "databricks": {
      "eggLibraries": [],
      "jarLibraries": [],
      "mavenLibraries": [],
      "pypiLibraries": [],
      "rcranLibraries": []
    },
    "docker": {
      "arguments": [],
      "baseDockerfile": null,
      "baseImage": "mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04:20200821.v1",
      "baseImageRegistry": {
        "address": null,
        "password": null,
        "registryIdentity": null,
        "username": null
      },
      "enabled": false,
      "platform": {
        "architecture": "amd64",
        "os": "Linux"
      },
      "sharedVolumes": true,
      "shmSize": null
    },
    "environmentVariables": {
      "EXAMPLE_ENV_VAR": "EXAMPLE_VALUE"
    },
    "inferencingStackVersion": null,
    "name": "AzureML-TensorFlow-2.2-GPU",
    "python": {
      "baseCondaEnvironment": null,
      "condaDependencies": {
        "channels": [
          "conda-forge"
        ],
        "dependencies": [
          "python=3.6.2",
          {
            "pip": [
              "azureml-core==1.13.0",
              "azureml-defaults==1.13.0",
              "azureml-telemetry==1.13.0",
              "azureml-train-restclients-hyperdrive==1.13.0",
              "azureml-train-core==1.13.0",
              "tensorflow-gpu==2.2.0",
              "horovod==0.19.1"
            ]
          }
        ],
        "name": "azureml_c58bf35e1b26936aac12c7976488df1f"
      },
      "condaDependenciesFile": null,
      "interpreterPath": "python",
      "userManagedDependencies": false
    },
    "r": null,
    "spark": {
      "packages": [],
      "precachePackages": true,
      "repositories": []
    },
    "version": "4"
  }
# History details.
history:
# Enable history tracking -- this allows status, logs, metrics, and outputs
# to be collected for a run.
  outputCollection: true
# Whether to take snapshots for history.
  snapshotProject: true
# Directories to sync with FileWatcher.
  directoriesToWatch:
  - logs
# Spark configuration details.
spark:
# The Spark configuration.
  configuration:
    spark.app.name: Azure ML Experiment
    spark.yarn.maxAppAttempts: 1
# HDI details.
hdi:
# Yarn deploy mode. Options are cluster and client.
  yarnDeployMode: cluster
# Tensorflow details.
tensorflow:
# The number of worker tasks.
  workerCount: 1
# The number of parameter server tasks.
  parameterServerCount: 1
# Mpi details.
mpi:
# When using MPI, number of processes per node.
  processCountPerNode: 1
# ParallelTask details.
paralleltask:
# Maximum number of retries per worker. Default 0.
  maxRetriesPerWorker: 0
# The number of workers/processes per node. Default 1.
  workerCountPerNode: 1
# Worker exit codes to terminate job.
  terminalExitCodes:
# data reference configuration details
dataReferences: {}
# The configuration that describes how to make data available for the run.
data: {}
# The configuration that describes how to save and track outputs for the run
outputData: {}
# Project share datastore reference.
sourceDirectoryDataStore:
# AmlCompute details.
amlcompute:
# VM size of the Cluster to be created.Allowed values are Azure vm sizes.The list of vm sizes is available in 'https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-sizes-specs
  vmSize:
# VM priority of the Cluster to be created. Allowed values are:"dedicated" , "lowpriority".
  vmPriority:
# A bool that indicates if the cluster has to be retained after job completion.
  retainCluster: false
# Name of the cluster to be created. If not specified, runId will be used as cluster name.
  name:
# Maximum number of nodes in the AmlCompute cluster to be created. Minimum number of nodes will always be set to 0.
  clusterMaxNodeCount:
